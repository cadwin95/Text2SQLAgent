# integrated_api_server.py
# ========================
# AgentChain + Text2DFQueryAgent í†µí•© API ì„œë²„
# - ì‹¤ì œ LLM ê¸°ë°˜ Text2SQL ë³€í™˜
# - KOSIS API ì—°ë™
# - DataFrame ê¸°ë°˜ ë°ì´í„° ë¶„ì„
# - ê³„íš-ì‹¤í–‰-ë°˜ì„± íŒŒì´í”„ë¼ì¸

import uvicorn
import os
import json
import asyncio
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any, AsyncGenerator
import time

# ë¡œì»¬ ëª¨ë“ˆ import (ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€)
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agent.agent_chain import AgentChain
from agent.text2sql_agent import Text2DFQueryAgent
import pandas as pd

# FastAPI ì•± ì„¤ì •
app = FastAPI(
    title="Text2SQL Agent API Server",
    description="AgentChainê³¼ Text2DFQueryAgentë¥¼ í†µí•©í•œ ì‹¤ì œ Text2SQL ë¶„ì„ ì„œë²„",
    version="2.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", 
        "http://127.0.0.1:3000",
        "http://10.150.1.221:3000",
        "http://10.150.1.221:3001"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI í˜¸í™˜ API ëª¨ë¸ ì •ì˜
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    max_tokens: Optional[int] = 512
    temperature: Optional[float] = 0.1

class ChatCompletionResponseChoice(BaseModel):
    index: int
    message: ChatMessage

class ChatCompletionResponse(BaseModel):
    id: str = "chatcmpl-agent"
    object: str = "chat.completion"
    model: str = "text2sql-agent"
    choices: List[ChatCompletionResponseChoice]

# ì „ì—­ AgentChain ì¸ìŠ¤í„´ìŠ¤
agent_chain = None

def initialize_agent():
    """AgentChain ì´ˆê¸°í™”"""
    global agent_chain
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ LLM ì„¤ì • ì½ê¸°
        backend = os.environ.get("LLM_BACKEND", "openai")
        model = os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo")
        
        print(f"ğŸ¤– AgentChain ì´ˆê¸°í™” ì¤‘... (backend: {backend}, model: {model})")
        agent_chain = AgentChain(backend=backend, model=model)
        print("âœ… AgentChain ì´ˆê¸°í™” ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ AgentChain ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        agent_chain = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    initialize_agent()

@app.get("/")
def read_root():
    return {
        "message": "Text2SQL Agent API Serverê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
        "status": "healthy",
        "agent_status": "ready" if agent_chain else "not_initialized",
        "endpoints": ["/v1/chat/completions", "/health", "/agent/status"],
        "features": [
            "ìì—°ì–´ â†’ SQL ë³€í™˜",
            "KOSIS API ì—°ë™",
            "DataFrame ê¸°ë°˜ ë¶„ì„",
            "ê³„íš-ì‹¤í–‰-ë°˜ì„± íŒŒì´í”„ë¼ì¸"
        ]
    }

@app.get("/health")
def health_check():
    return {
        "status": "healthy", 
        "timestamp": time.time(),
        "agent_ready": agent_chain is not None
    }

@app.get("/agent/status")
def agent_status():
    """AgentChain ìƒíƒœ í™•ì¸"""
    if not agent_chain:
        return {"status": "not_initialized", "dataframes": []}
    
    return {
        "status": "ready",
        "backend": agent_chain.backend,
        "model": agent_chain.model,
        "available_dataframes": list(agent_chain.df_agent.dataframes.keys()),
        "dataframe_shapes": {
            name: df.shape for name, df in agent_chain.df_agent.dataframes.items()
        }
    }

@app.post("/v1/chat/completions", response_model=ChatCompletionResponse)
async def chat_completions(request: ChatCompletionRequest):
    """OpenAI í˜¸í™˜ ì±„íŒ… ì™„ë£Œ API"""
    try:
        if not agent_chain:
            raise HTTPException(status_code=503, detail="AgentChainì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
        user_message = ""
        for message in request.messages:
            if message.role == "user":
                user_message = message.content
                break
        
        if not user_message:
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆì˜: {user_message}")
        
        # AgentChain ì‹¤í–‰
        result = await run_agent_chain(user_message)
        
        # ì‘ë‹µ ìƒì„±
        response_content = format_agent_response(result)
        
        response = ChatCompletionResponse(
            choices=[
                ChatCompletionResponseChoice(
                    index=0,
                    message=ChatMessage(
                        role="assistant",
                        content=response_content
                    )
                )
            ]
        )
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")

async def run_agent_chain(question: str) -> Dict[str, Any]:
    """AgentChain ë¹„ë™ê¸° ì‹¤í–‰"""
    try:
        # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ (ì‹¤ì œë¡œëŠ” ë™ì ìœ¼ë¡œ ìƒì„±í•´ì•¼ í•¨)
        schema = """
        ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:
        - KOSIS í†µê³„ ë°ì´í„° (fetch_kosis_data ë„êµ¬ ì‚¬ìš©)
        - ê¸°ì¡´ ë¡œë“œëœ DataFrameë“¤
        """
        
        # AgentChain ì‹¤í–‰ (ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            agent_chain.run, 
            question
        )
        
        return result
        
    except Exception as e:
        return {
            "history": [],
            "remaining_plan": [],
            "final_result": None,
            "error": str(e)
        }

def format_agent_response(result: Dict[str, Any]) -> str:
    """AgentChain ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    try:
        history = result.get("history", [])
        final_result = result.get("final_result")
        error = result.get("error")
        
        if error:
            return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}"
        
        if not history:
            return "ğŸ“Š ë¶„ì„ì„ ìˆ˜í–‰í–ˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ì‘ë‹µ êµ¬ì„±
        response_parts = []
        
        # ì‹¤í–‰ëœ ë‹¨ê³„ë“¤ ìš”ì•½
        if len(history) > 1:
            response_parts.append("ğŸ”„ **ì‹¤í–‰ëœ ë¶„ì„ ë‹¨ê³„:**")
            for i, step in enumerate(history, 1):
                step_type = step.get("type", "unknown")
                description = step.get("description", "")
                step_error = step.get("error")
                
                if step_error:
                    response_parts.append(f"{i}. {description} âŒ (ì˜¤ë¥˜: {step_error})")
                else:
                    response_parts.append(f"{i}. {description} âœ…")
        
        # ìµœì¢… ê²°ê³¼
        if final_result:
            response_parts.append("\nğŸ“ˆ **ë¶„ì„ ê²°ê³¼:**")
            
            # DataFrame ê²°ê³¼ ì²˜ë¦¬
            if isinstance(final_result, dict):
                if "columns" in final_result and "rows" in final_result:
                    columns = final_result["columns"]
                    rows = final_result["rows"]
                    
                    if columns and rows:
                        # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                        response_parts.append("```")
                        response_parts.append(" | ".join(columns))
                        response_parts.append("-" * (len(" | ".join(columns))))
                        
                        for row in rows[:10]:  # ìµœëŒ€ 10í–‰ë§Œ í‘œì‹œ
                            response_parts.append(" | ".join(str(cell) for cell in row))
                        
                        if len(rows) > 10:
                            response_parts.append(f"... (ì´ {len(rows)}í–‰ ì¤‘ 10í–‰ í‘œì‹œ)")
                        
                        response_parts.append("```")
                    else:
                        response_parts.append("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                elif "query_code" in final_result:
                    query_code = final_result["query_code"]
                    if query_code:
                        response_parts.append("**ìƒì„±ëœ ì¿¼ë¦¬ ì½”ë“œ:**")
                        response_parts.append(f"```python\n{query_code}\n```")
                
                elif "msg" in final_result:
                    response_parts.append(final_result["msg"])
                else:
                    response_parts.append(str(final_result))
            else:
                response_parts.append(str(final_result))
        
        return "\n".join(response_parts) if response_parts else "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        return f"ì‘ë‹µ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def generate_chart_data(dataframes: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
    """DataFrame ë°ì´í„°ë¡œë¶€í„° ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
    try:
        # ì‚¬ìš© ê°€ëŠ¥í•œ DataFrameì´ ìˆëŠ”ì§€ í™•ì¸
        if not dataframes:
            return None
        
        # ì²« ë²ˆì§¸ DataFrame ì‚¬ìš© (ì¼ë°˜ì ìœ¼ë¡œ fetch_kosis_dataë¡œ ìƒì„±ëœ ê²ƒ)
        df_name = next(iter(dataframes.keys()))
        df = dataframes[df_name]
        
        if df.empty:
            return None
        
        # ì¸êµ¬ ë°ì´í„°ì¸ ê²½ìš° (PRD_DE, DT ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
        if 'PRD_DE' in df.columns and 'DT' in df.columns:
            # ì—°ë„ë³„ ë°ì´í„° ì¶”ì¶œ
            years = df['PRD_DE'].astype(str).tolist()
            values = pd.to_numeric(df['DT'], errors='coerce').tolist()
            
            # ì„±ì¥ë¥  ê³„ì‚°
            growth_rates = []
            for i in range(1, len(values)):
                if values[i-1] and values[i]:
                    growth_rate = ((values[i] - values[i-1]) / values[i-1]) * 100
                    growth_rates.append(round(growth_rate, 2))
                else:
                    growth_rates.append(0)
            
            # ì²« ë²ˆì§¸ ì—°ë„ëŠ” ì„±ì¥ë¥ ì´ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
            growth_rates.insert(0, 0)
            
            return {
                'type': 'line',
                'title': 'ìµœê·¼ 5ë…„ê°„ ì¸êµ¬ ì„±ì¥ë¥  ì¶”ì´ (GDP ì„±ì¥ë¥  ëŒ€ì²´)',
                'data': {
                    'labels': years,
                    'datasets': [
                        {
                            'label': 'ì¸êµ¬ ì„±ì¥ë¥  (%)',
                            'data': growth_rates,
                            'borderColor': 'rgb(75, 192, 192)',
                            'backgroundColor': 'rgba(75, 192, 192, 0.2)',
                            'borderWidth': 2,
                            'tension': 0.1
                        }
                    ]
                },
                'options': {
                    'scales': {
                        'y': {
                            'beginAtZero': True,
                            'title': {
                                'display': True,
                                'text': 'ì„±ì¥ë¥  (%)'
                            }
                        },
                        'x': {
                            'title': {
                                'display': True,
                                'text': 'ì—°ë„'
                            }
                        }
                    }
                }
            }
        
        return None
        
    except Exception as e:
        print(f"ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
        return None

@app.post("/v1/chat/stream")
async def chat_stream(request: ChatCompletionRequest):
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì™„ë£Œ API - íˆ´ í˜¸ì¶œ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡"""
    if not agent_chain:
        raise HTTPException(status_code=503, detail="AgentChainì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = ""
    for message in request.messages:
        if message.role == "user":
            user_message = message.content
            break
    
    if not user_message:
        raise HTTPException(status_code=400, detail="ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    async def stream_generator() -> AsyncGenerator[str, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±ê¸°"""
        try:
            print(f"ğŸ“ ì‚¬ìš©ì ì§ˆì˜: {user_message}")
            
            # ì‹œì‘ ë©”ì‹œì§€
            yield f"data: {json.dumps({'type': 'start', 'message': 'ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...'}, ensure_ascii=False)}\n\n"
            
            # AgentChain ì‹¤í–‰ (ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¬ë° ë²„ì „)
            async for update in run_agent_chain_streaming(user_message):
                yield f"data: {json.dumps(update, ensure_ascii=False)}\n\n"
            
            # ì™„ë£Œ ë©”ì‹œì§€
            yield f"data: {json.dumps({'type': 'done', 'message': 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            error_msg = {
                'type': 'error',
                'message': f'âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'
            }
            yield f"data: {json.dumps(error_msg, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        stream_generator(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/plain; charset=utf-8"
        }
    )

async def run_agent_chain_streaming(question: str) -> AsyncGenerator[Dict[str, Any], None]:
    """AgentChain ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
    try:
        # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ìƒì„±
        schema = f"""
ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:
- KOSIS í†µê³„ ë°ì´í„° (fetch_kosis_data ë„êµ¬ ì‚¬ìš©)
- ê¸°ì¡´ ë¡œë“œëœ DataFrameë“¤: {list(agent_chain.df_agent.dataframes.keys())}
"""
        
        # 1ë‹¨ê³„: ê³„íš ìƒì„±
        yield {
            'type': 'planning',
            'message': 'ğŸ¯ ë¶„ì„ ê³„íšì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤...',
            'status': 'running'
        }
        
        # ì‹¤ì œ ê³„íš ìƒì„±
        steps = await asyncio.get_event_loop().run_in_executor(
            None, agent_chain.plan_with_llm, question, schema
        )
        
        yield {
            'type': 'planning',
            'message': f'âœ… ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(steps)}ê°œ ë‹¨ê³„',
            'status': 'completed',
            'data': {'steps': [step.get('description', '') for step in steps]}
        }
        
        # 2ë‹¨ê³„: ê° ë‹¨ê³„ ì‹¤í–‰
        for i, step in enumerate(steps, 1):
            step_type = step.get('type', 'unknown')
            description = step.get('description', '')
            
            # ë‹¨ê³„ ì‹¤í–‰
            try:
                if step_type == 'tool_call':
                    # íˆ´ í˜¸ì¶œ í‘œì‹œ
                    tool_name = step.get('tool_name', 'unknown')
                    yield {
                        'type': 'tool_call',
                        'tool_name': tool_name,
                        'step_number': i,
                        'message': f'ğŸ”§ **ë„êµ¬ í˜¸ì¶œ: {tool_name}**',
                        'description': description,
                        'status': 'running'
                    }
                    
                    # ì‹¤ì œ íˆ´ ì‹¤í–‰
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, agent_chain.execute_step, step
                    )
                    
                    if result.get('error'):
                        yield {
                            'type': 'tool_call',
                            'tool_name': tool_name,
                            'step_number': i,
                            'message': f'âŒ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {result["error"]}',
                            'status': 'error'
                        }
                    else:
                        yield {
                            'type': 'tool_call',
                            'tool_name': tool_name,
                            'step_number': i,
                            'message': f'âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: {tool_name}',
                            'status': 'completed',
                            'data': result
                        }
                
                elif step_type == 'query':
                    # DataFrame ì¿¼ë¦¬ ì‹¤í–‰
                    yield {
                        'type': 'query',
                        'step_number': i,
                        'message': f'ğŸ“Š **ë°ì´í„° ì¿¼ë¦¬**\nğŸ“Š ë°ì´í„° ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...',
                        'description': description,
                        'status': 'running'
                    }
                    
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, agent_chain.execute_step, step
                    )
                    
                    if result.get('error'):
                        yield {
                            'type': 'query',
                            'step_number': i,
                            'message': f'âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {result["error"]}',
                            'status': 'error'
                        }
                    else:
                        yield {
                            'type': 'query',
                            'step_number': i,
                            'message': f'âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ',
                            'status': 'completed',
                            'data': result
                        }
                
                elif step_type == 'visualization':
                    # ì‹œê°í™” ë‹¨ê³„ - ì‹¤ì œ ì°¨íŠ¸ ë°ì´í„° ìƒì„±
                    chart_data = generate_chart_data(agent_chain.df_agent.dataframes)
                    yield {
                        'type': 'visualization',
                        'step_number': i,
                        'message': f'ğŸ“ˆ **ì‹œê°í™” ìƒì„±**\n{description}',
                        'description': description,
                        'status': 'completed',
                        'chart_data': chart_data
                    }
                
                else:
                    # ê¸°íƒ€ ë‹¨ê³„ ì‹¤í–‰
                    result = await asyncio.get_event_loop().run_in_executor(
                        None, agent_chain.execute_step, step
                    )
                    
                    status = 'error' if result.get('error') else 'completed'
                    emoji = 'âŒ' if result.get('error') else 'âœ…'
                    
                    yield {
                        'type': 'step',
                        'step_number': i,
                        'message': f'{emoji} **ë‹¨ê³„ {i}**: {description}',
                        'status': status,
                        'data': result
                    }
                
            except Exception as e:
                yield {
                    'type': 'step',
                    'step_number': i,
                    'message': f'âŒ ë‹¨ê³„ {i} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}',
                    'status': 'error'
                }
        
        # 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìƒì„±
        yield {
            'type': 'result',
            'message': 'ğŸ“ˆ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...',
            'status': 'running'
        }
        
        # ì‹¤í–‰ëœ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ë¥¼ ìš”ì•½
        executed_steps = []
        for i, step in enumerate(steps, 1):
            step_desc = step.get('description', f'ë‹¨ê³„ {i}')
            executed_steps.append(f"{i}. {step_desc} âœ…")
        
        # ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„± (ì´ë¯¸ ì‹¤í–‰ëœ ë‹¨ê³„ë“¤ ê¸°ë°˜)
        summary_message = f"""
ğŸ”„ **ì‹¤í–‰ëœ ë¶„ì„ ë‹¨ê³„:**
{chr(10).join(executed_steps)}

ğŸ“ˆ **ë¶„ì„ ê²°ê³¼:**
{step.get('type', '').replace('_', ' ').title()} ë‹¨ê³„ ì™„ë£Œ
"""
        
        # ì‹œê°í™” ë‹¨ê³„ê°€ ìˆì—ˆë‹¤ë©´ ë”ë¯¸ ì‹¤í–‰
        if any('visualization' in step.get('type', '') for step in steps):
            summary_message += "\nì‹œê°í™”(line_chart) ë‹¨ê³„ dummy ì‹¤í–‰"
        
        yield {
            'type': 'result',
            'message': summary_message.strip(),
            'status': 'completed',
            'data': {
                'executed_steps': executed_steps,
                'total_steps': len(steps),
                'dataframes_available': list(agent_chain.df_agent.dataframes.keys())
            }
        }
        
    except Exception as e:
        yield {
            'type': 'error',
            'message': f'âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
            'status': 'error'
        }

@app.post("/agent/query")
async def direct_query(request: Dict[str, Any]):
    """ì§ì ‘ ì¿¼ë¦¬ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)"""
    try:
        if not agent_chain:
            raise HTTPException(status_code=503, detail="AgentChainì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        question = request.get("question")
        if not question:
            raise HTTPException(status_code=400, detail="question íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        result = await run_agent_chain(question)
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print("ğŸš€ Text2SQL Agent API Server ì‹œì‘ ì¤‘...")
    print("ğŸ“ URL: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ”— í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™: http://localhost:3000")
    print("\nğŸ”§ í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜:")
    print("- OPENAI_API_KEY: OpenAI API í‚¤")
    print("- KOSIS_OPEN_API_KEY: KOSIS API í‚¤ (ì„ íƒì‚¬í•­)")
    print("- LLM_BACKEND: LLM ë°±ì—”ë“œ (ê¸°ë³¸ê°’: openai)")
    print("- OPENAI_MODEL: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-3.5-turbo)")
    
    uvicorn.run(
        "integrated_api_server:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    ) 