# gguf.py
# -------
# 로컬 gguf(예: llama.cpp, koboldcpp 등) 기반 LLM 백엔드 구현 파일
# - base.py의 LLMClient 추상화를 상속하여 구현
# - 로컬 엔진 실행, 파이프/REST 통신, generate/chat 메서드 제공
# - MCP 서버/Agent에서 로컬 LLM 엔진(gguf 포맷) 연동 시 사용
# - 성능/리소스 관리, 엔진별 옵션 지원 등 포함
# - 자세한 설계/구현 규칙은 .cursor/rules/rl-text2sql-public-api.md 참고

# ... (구현 예정)
pass

